# HG changeset patch
# Parent b046b1b2e283e5a82a0474cc72d717f0964234f2
try: -b o -p android -u reftest,crashtest,xpcshell,jsreftest,jetpack,marionette,mochitests,reftest-1,reftest-2,reftest-3,reftest-4,jsreftest-1,jsreftest-2,jsreftest-3,crashtest-2,crashtest-3,mochitest-6,mochitest-7,mochitest-8,robocop -t none

diff --git a/content/media/webrtc/MediaEngine.h b/content/media/webrtc/MediaEngine.h
--- a/content/media/webrtc/MediaEngine.h
+++ b/content/media/webrtc/MediaEngine.h
@@ -23,16 +23,21 @@ class MediaEngineAudioSource;
 
 enum MediaEngineState {
   kAllocated,
   kStarted,
   kStopped,
   kReleased
 };
 
+/**
+ * Callback type for Snapshot().
+ */
+typedef void (*SnapshotCallback)(already_AddRefed<nsIDOMFile> cFile, void* cData);
+
 class MediaEngine
 {
 public:
   virtual ~MediaEngine() {};
 
   /* Populate an array of video sources in the nsTArray. Also include devices
    * that are currently unavailable. */
   virtual void EnumerateVideoDevices(nsTArray<nsRefPtr<MediaEngineVideoSource> >*) = 0;
@@ -64,19 +69,20 @@ public:
 
   /* Start the device and add the track to the provided SourceMediaStream, with
    * the provided TrackID. You may start appending data to the track
    * immediately after. */
   virtual nsresult Start(SourceMediaStream*, TrackID) = 0;
 
   /* Take a snapshot from this source. In the case of video this is a single
    * image, and for audio, it is a snippet lasting aDuration milliseconds. The
-   * duration argument is ignored for a MediaEngineVideoSource.
+   * duration argument is ignored for a MediaEngineVideoSource. Return the
+   * picture as an alrady_AddRefed<nsIDOMFile> via the callback.
    */
-  virtual nsresult Snapshot(uint32_t aDuration, nsIDOMFile** aFile) = 0;
+  virtual nsresult Snapshot(uint32_t aDuration, SnapshotCallback aCb, void* aData) = 0;
 
   /* Stop the device and release the corresponding MediaStream */
   virtual nsresult Stop() = 0;
 
   /* It is an error to call Start() before an Allocate(), and Stop() before
    * a Start(). Only Allocate() may be called after a Deallocate(). */
 };
 
diff --git a/content/media/webrtc/MediaEngineDefault.cpp b/content/media/webrtc/MediaEngineDefault.cpp
--- a/content/media/webrtc/MediaEngineDefault.cpp
+++ b/content/media/webrtc/MediaEngineDefault.cpp
@@ -21,16 +21,48 @@
 
 namespace mozilla {
 
 NS_IMPL_THREADSAFE_ISUPPORTS1(MediaEngineDefaultVideoSource, nsITimerCallback)
 /**
  * Default video source.
  */
 
+// On Android, the picture must be obtained on the main thread.
+#ifdef MOZ_WIDGET_ANDROID
+class AndroidPictureRunnable : public nsRunnable {
+public:
+  AndroidPictureRunnable(SnapshotCallback aCb, void* aData)
+  : mCb(aCb)
+  , mData(aData) {}
+  ~AndroidPictureRunnable() {}
+
+  nsresult
+  Run()
+  {
+    nsAutoString filePath;
+    AndroidBridge::Bridge()->ShowFilePickerForMimeType(
+      filePath, NS_LITERAL_STRING("image/*")
+    );
+
+    nsCOMPtr<nsIFile> file;
+    nsresult rv = NS_NewLocalFile(filePath, false, getter_AddRefs(file));
+    NS_ENSURE_SUCCESS(rv, rv);
+
+    nsRefPtr<nsIDOMFile> domFile = new nsDOMFileFile(file);
+    mCb(domFile.forget(), mData);
+    return NS_OK;
+  }
+
+private:
+  SnapshotCallback mCb;
+  void* mData;
+};
+#endif
+
 // Cannot be initialized in the class definition
 const MediaEngineVideoOptions MediaEngineDefaultVideoSource::mOpts = {
   DEFAULT_WIDTH,
   DEFAULT_HEIGHT,
   DEFAULT_FPS,
   kVideoCodecI420
 };
 
@@ -161,35 +193,29 @@ MediaEngineDefaultVideoSource::Stop()
   mSource->EndTrack(mTrackID);
   mSource->Finish();
 
   mState = kStopped;
   return NS_OK;
 }
 
 nsresult
-MediaEngineDefaultVideoSource::Snapshot(uint32_t aDuration, nsIDOMFile** aFile)
+MediaEngineDefaultVideoSource::Snapshot(uint32_t aDuration, SnapshotCallback aCb, void* aData)
 {
-  *aFile = nullptr;
-
 #ifndef MOZ_WIDGET_ANDROID
   return NS_ERROR_NOT_IMPLEMENTED;
 #else
   if (!AndroidBridge::Bridge()) {
     return NS_ERROR_UNEXPECTED;
   }
 
-  nsAutoString filePath;
-  AndroidBridge::Bridge()->ShowFilePickerForMimeType(filePath, NS_LITERAL_STRING("image/*"));
-
-  nsCOMPtr<nsIFile> file;
-  nsresult rv = NS_NewLocalFile(filePath, false, getter_AddRefs(file));
-  NS_ENSURE_SUCCESS(rv, rv);
-
-  NS_ADDREF(*aFile = new nsDOMFileFile(file));
+  // AndroidBridge only works on the main thread.
+  nsRefPtr<AndroidPictureRunnable> runnable =
+    new AndroidPictureRunnable(aCb, aData);
+  NS_DispatchToMainThread(runnable, NS_DISPATCH_NORMAL);
   return NS_OK;
 #endif
 }
 
 NS_IMETHODIMP
 MediaEngineDefaultVideoSource::Notify(nsITimer* aTimer)
 {
   VideoSegment segment;
@@ -288,17 +314,18 @@ MediaEngineDefaultAudioSource::Stop()
   mSource->EndTrack(mTrackID);
   mSource->Finish();
 
   mState = kStopped;
   return NS_OK;
 }
 
 nsresult
-MediaEngineDefaultAudioSource::Snapshot(uint32_t aDuration, nsIDOMFile** aFile)
+MediaEngineDefaultAudioSource::Snapshot(uint32_t aDuration,
+  SnapshotCallback aCb, void* aData)
 {
    return NS_ERROR_NOT_IMPLEMENTED;
 }
 
 NS_IMETHODIMP
 MediaEngineDefaultAudioSource::Notify(nsITimer* aTimer)
 {
   AudioSegment segment;
diff --git a/content/media/webrtc/MediaEngineDefault.h b/content/media/webrtc/MediaEngineDefault.h
--- a/content/media/webrtc/MediaEngineDefault.h
+++ b/content/media/webrtc/MediaEngineDefault.h
@@ -40,17 +40,17 @@ public:
   virtual void GetUUID(nsAString&);
 
   virtual const MediaEngineVideoOptions *GetOptions();
   virtual nsresult Allocate();
 
   virtual nsresult Deallocate();
   virtual nsresult Start(SourceMediaStream*, TrackID);
   virtual nsresult Stop();
-  virtual nsresult Snapshot(uint32_t aDuration, nsIDOMFile** aFile);
+  virtual nsresult Snapshot(uint32_t aDuration, SnapshotCallback aCb, void* aData);
 
   NS_DECL_ISUPPORTS
   NS_DECL_NSITIMERCALLBACK
 
   // Need something better...
   static const int DEFAULT_WIDTH=640;
   static const int DEFAULT_HEIGHT=480;
   static const int DEFAULT_FPS=30;
@@ -76,17 +76,17 @@ public:
   virtual void GetName(nsAString&);
   virtual void GetUUID(nsAString&);
 
   virtual nsresult Allocate();
 
   virtual nsresult Deallocate();
   virtual nsresult Start(SourceMediaStream*, TrackID);
   virtual nsresult Stop();
-  virtual nsresult Snapshot(uint32_t aDuration, nsIDOMFile** aFile);
+  virtual nsresult Snapshot(uint32_t aDuration, SnapshotCallback aCb, void* aData);
 
   NS_DECL_ISUPPORTS
   NS_DECL_NSITIMERCALLBACK
 
 protected:
   TrackID mTrackID;
   nsCOMPtr<nsITimer> mTimer;
 
diff --git a/content/media/webrtc/MediaEngineWebRTC.h b/content/media/webrtc/MediaEngineWebRTC.h
--- a/content/media/webrtc/MediaEngineWebRTC.h
+++ b/content/media/webrtc/MediaEngineWebRTC.h
@@ -55,28 +55,31 @@ class MediaEngineWebRTCVideoSource : pub
 public:
   static const int DEFAULT_VIDEO_FPS = 30;
   static const int DEFAULT_MIN_VIDEO_FPS = 10;
 
   // ViEExternalRenderer.
   virtual int FrameSizeChange(unsigned int, unsigned int, unsigned int);
   virtual int DeliverFrame(unsigned char*, int, uint32_t, int64_t);
 
+  // For snapshots.
+  virtual void DeliverSnapshotFrame();
+
   MediaEngineWebRTCVideoSource(webrtc::VideoEngine* videoEnginePtr,
     int index, int aMinFps = DEFAULT_MIN_VIDEO_FPS);
   ~MediaEngineWebRTCVideoSource();
 
   virtual void GetName(nsAString&);
   virtual void GetUUID(nsAString&);
   virtual const MediaEngineVideoOptions *GetOptions();
   virtual nsresult Allocate();
   virtual nsresult Deallocate();
   virtual nsresult Start(SourceMediaStream*, TrackID);
   virtual nsresult Stop();
-  virtual nsresult Snapshot(uint32_t aDuration, nsIDOMFile** aFile);
+  virtual nsresult Snapshot(uint32_t aDuration, SnapshotCallback aCb, void* aData);
 
   NS_DECL_ISUPPORTS
 
   // This runnable is for creating a temporary file on the main thread.
   NS_IMETHODIMP
   Run()
   {
     nsCOMPtr<nsIFile> tmp;
@@ -98,17 +101,16 @@ private:
   static const unsigned int KMaxDeviceNameLength = 128;
   static const unsigned int KMaxUniqueIdLength = 256;
 
   // Initialize the needed Video engine interfaces.
   void Init();
   void Shutdown();
 
   // Engine variables.
-
   webrtc::VideoEngine* mVideoEngine; // Weak reference, don't free.
   webrtc::ViEBase* mViEBase;
   webrtc::ViECapture* mViECapture;
   webrtc::ViERender* mViERender;
   webrtc::CaptureCapability mCapability; // Doesn't work on OS X.
 
   int mCaptureIndex;
   bool mCapabilityChosen;
@@ -117,24 +119,25 @@ private:
 
   MediaEngineState mState;
   mozilla::ReentrantMonitor mMonitor; // Monitor for processing WebRTC frames.
   SourceMediaStream* mSource;
 
   int mFps; // Track rate (30 fps by default)
   int mMinFps; // Min rate we want to accept
   bool mInitDone;
-  bool mInSnapshotMode;
+
+  // Snapshot variables.
+  bool mSnapshotMode;
+  void* mSnapshotData;
   nsString* mSnapshotPath;
+  SnapshotCallback mSnapshotCb;
 
   nsRefPtr<layers::ImageContainer> mImageContainer;
 
-  PRLock* mSnapshotLock;
-  PRCondVar* mSnapshotCondVar;
-
   // These are in UTF-8 but webrtc api uses char arrays
   char mDeviceName[KMaxDeviceNameLength];
   char mUniqueId[KMaxUniqueIdLength];
 
   void ChooseCapability(uint32_t aWidth, uint32_t aHeight, uint32_t aMinFPS);
   MediaEngineVideoOptions mOpts;
 };
 
@@ -161,17 +164,17 @@ public:
 
   virtual void GetName(nsAString&);
   virtual void GetUUID(nsAString&);
 
   virtual nsresult Allocate();
   virtual nsresult Deallocate();
   virtual nsresult Start(SourceMediaStream*, TrackID);
   virtual nsresult Stop();
-  virtual nsresult Snapshot(uint32_t aDuration, nsIDOMFile** aFile);
+  virtual nsresult Snapshot(uint32_t aDuration, SnapshotCallback aCb, void* aData);
 
   // VoEMediaProcess.
   void Process(const int channel, const webrtc::ProcessingTypes type,
                WebRtc_Word16 audio10ms[], const int length,
                const int samplingFreq, const bool isStereo);
 
   NS_DECL_ISUPPORTS
 
diff --git a/content/media/webrtc/MediaEngineWebRTCAudio.cpp b/content/media/webrtc/MediaEngineWebRTCAudio.cpp
--- a/content/media/webrtc/MediaEngineWebRTCAudio.cpp
+++ b/content/media/webrtc/MediaEngineWebRTCAudio.cpp
@@ -163,17 +163,18 @@ MediaEngineWebRTCAudioSource::Stop()
     return NS_ERROR_FAILURE;
   }
 
   mState = kStopped;
   return NS_OK;
 }
 
 nsresult
-MediaEngineWebRTCAudioSource::Snapshot(uint32_t aDuration, nsIDOMFile** aFile)
+MediaEngineWebRTCAudioSource::Snapshot(uint32_t aDuration,
+  SnapshotCallback aCb, void* aData)
 {
    return NS_ERROR_NOT_IMPLEMENTED;
 }
 
 
 void
 MediaEngineWebRTCAudioSource::Shutdown()
 {
diff --git a/content/media/webrtc/MediaEngineWebRTCVideo.cpp b/content/media/webrtc/MediaEngineWebRTCVideo.cpp
--- a/content/media/webrtc/MediaEngineWebRTCVideo.cpp
+++ b/content/media/webrtc/MediaEngineWebRTCVideo.cpp
@@ -21,17 +21,17 @@ MediaEngineWebRTCVideoSource::MediaEngin
   , mCapabilityChosen(false)
   , mWidth(640)
   , mHeight(480)
   , mState(kReleased)
   , mMonitor("WebRTCCamera.Monitor")
   , mFps(DEFAULT_VIDEO_FPS)
   , mMinFps(aMinFps)
   , mInitDone(false)
-  , mInSnapshotMode(false)
+  , mSnapshotMode(false)
   , mSnapshotPath(NULL)
 {
   Init();
 }
 
 MediaEngineWebRTCVideoSource::~MediaEngineWebRTCVideoSource()
 {
   Shutdown();
@@ -45,26 +45,23 @@ MediaEngineWebRTCVideoSource::FrameSizeC
   mWidth = w;
   mHeight = h;
   return 0;
 }
 
 // ViEExternalRenderer Callback. Process every incoming frame here.
 int
 MediaEngineWebRTCVideoSource::DeliverFrame(
-   unsigned char* buffer, int size, uint32_t time_stamp, int64_t render_time)
+  unsigned char* buffer, int size, uint32_t time_stamp, int64_t render_time)
 {
   ReentrantMonitorAutoEnter enter(mMonitor);
 
-  if (mInSnapshotMode) {
-    // Set the condition variable to false and notify Snapshot().
-    PR_Lock(mSnapshotLock);
-    mInSnapshotMode = false;
-    PR_NotifyCondVar(mSnapshotCondVar);
-    PR_Unlock(mSnapshotLock);
+  if (mSnapshotMode) {
+    printf("\n!!! in DeliverFrame, calling DeliverSnapshotFrame !!!\n");
+    DeliverSnapshotFrame();
     return 0;
   }
 
   // Check for proper state.
   if (mState != kStarted) {
     return 0;
   }
 
@@ -94,16 +91,72 @@ MediaEngineWebRTCVideoSource::DeliverFra
   videoImage->SetData(data);
 
   VideoSegment segment;
   segment.AppendFrame(image.forget(), 1, gfxIntSize(mWidth, mHeight));
   mSource->AppendToTrack(mTrackID, &(segment));
   return 0;
 }
 
+// If in snapshot mode, called by DeliverFrame. Creates a file, sets it to
+// the current frame and returns a nsIDOMFile via the provided callback.
+void
+MediaEngineWebRTCVideoSource::DeliverSnapshotFrame()
+{
+  // Create a temporary file on the main thread and put the snapshot in it.
+  // See Run() in MediaEngineWebRTCVideo.h (sets mSnapshotPath).
+  NS_DispatchToMainThread(this, NS_DISPATCH_SYNC);
+
+  nsCOMPtr<nsIFile> file;
+  nsCOMPtr<nsIDOMFile> domFile;
+  webrtc::ViEFile* vieFile;
+
+  if (!mSnapshotPath) {
+    printf("\n!!! mSnapshotPath failed !!!\n");
+    goto snapshotFailed;
+  }
+
+  vieFile = webrtc::ViEFile::GetInterface(mVideoEngine);
+  if (!vieFile) {
+    printf("\n!!! vieFile failed !!!\n");
+    goto snapshotFailed;
+  }
+
+  printf("\n!!! Calling GetCaptureDeviceSnapshot !!!\n");
+  if (vieFile->GetCaptureDeviceSnapshot(mCaptureIndex,
+    NS_ConvertUTF16toUTF8(*mSnapshotPath).get()) < 0) {
+    goto snapshotFailed;
+  }
+
+  // Stop the camera.
+  mViERender->StopRender(mCaptureIndex);
+  mViERender->RemoveRenderer(mCaptureIndex);
+  mState = kStopped;
+
+  // Create nsIFile from mSnapshotPath.
+  printf("\n!!! Creating nsIFile !!!\n");
+  NS_NewLocalFile(*mSnapshotPath, false, getter_AddRefs(file));
+
+  // Invoke the callback.
+  domFile = new nsDOMFileFile(file);
+  mSnapshotCb(domFile.forget(), mSnapshotData);
+  printf("\n!!! Delivered Callback !!!\n");
+
+snapshotFailed:
+  if (mSnapshotPath) {
+    delete mSnapshotPath;
+  }
+  mSnapshotCb = NULL;
+  mSnapshotPath = NULL;
+  mSnapshotData = NULL;
+  mSnapshotMode = false;
+
+  return;
+}
+
 void
 MediaEngineWebRTCVideoSource::ChooseCapability(uint32_t aWidth, uint32_t aHeight, uint32_t aMinFPS)
 {
   int num = mViECapture->NumberOfCapabilities(mUniqueId, KMaxUniqueIdLength);
 
   NS_WARN_IF_FALSE(!mCapabilityChosen,"Shouldn't select capability of a device twice");
 
   if (num <= 0) {
@@ -263,105 +316,56 @@ MediaEngineWebRTCVideoSource::Stop()
   mViERender->StopRender(mCaptureIndex);
   mViERender->RemoveRenderer(mCaptureIndex);
 
   mState = kStopped;
   return NS_OK;
 }
 
 nsresult
-MediaEngineWebRTCVideoSource::Snapshot(uint32_t aDuration, nsIDOMFile** aFile)
+MediaEngineWebRTCVideoSource::Snapshot(uint32_t aDuration,
+  SnapshotCallback aCb, void* aData)
 {
+  printf("\n!!! Received callback !!!\n");
   /**
    * To get a Snapshot we do the following:
-   * - Set a condition variable (mInSnapshotMode) to true
-   * - Attach the external renderer and start the camera
-   * - Wait for the condition variable to change to false
+   * - Set mInSnapshotMode to true, mSnapshotCb to aCb and mSnapshotData to aData.
+   * - Attach the external renderer and start the camera.
    *
    * Starting the camera has the effect of invoking DeliverFrame() when
    * the first frame arrives from the camera. We only need one frame for
-   * GetCaptureDeviceSnapshot to work, so we immediately set the condition
-   * variable to false and notify this method.
+   * GetCaptureDeviceSnapshot to work, so DeliverFrame will call
+   * DeliverSnapshotFrame(), which will proceed to convert the snapshot to a
+   * file and return it via the provided callback.
    *
-   * This causes the current thread to continue (PR_CondWaitVar will return),
-   * at which point we can grab a snapshot, convert it to a file and
-   * return from this function after cleaning up the temporary stream object
-   * and caling Stop() on the media source.
+   * DeliverFrame will also reset all the respective mSnapshot* member variables.
    */
-  *aFile = nullptr;
-  if (!mInitDone || mState != kAllocated) {
-    return NS_ERROR_FAILURE;
-  }
-
-  mSnapshotLock = PR_NewLock();
-  mSnapshotCondVar = PR_NewCondVar(mSnapshotLock);
-
-  PR_Lock(mSnapshotLock);
-  mInSnapshotMode = true;
+  mSnapshotCb = aCb;
+  mSnapshotMode = true;
+  mSnapshotData = aData;
 
   // Start the rendering (equivalent to calling Start(), but without a track).
   int error = 0;
   if (!mInitDone || mState != kAllocated) {
+    printf("\n!!! Error in mInitDone !!!\n");
     return NS_ERROR_FAILURE;
   }
+  printf("\n!!! Calling AddRenderer !!!\n");
   error = mViERender->AddRenderer(mCaptureIndex, webrtc::kVideoI420, (webrtc::ExternalRenderer*)this);
   if (error == -1) {
+    printf("\n!!! Error in AddRenderer !!!\n");
     return NS_ERROR_FAILURE;
   }
+  printf("\n!!! Calling StartRender !!!\n");
   error = mViERender->StartRender(mCaptureIndex);
   if (error == -1) {
+    printf("\n!!! Error in StartRender !!!\n");
     return NS_ERROR_FAILURE;
   }
 
-  // Wait for the condition variable, will be set in DeliverFrame.
-  // We use a while loop, because even if PR_WaitCondVar returns, it's not
-  // guaranteed that the condition variable changed.
-  while (mInSnapshotMode) {
-    PR_WaitCondVar(mSnapshotCondVar, PR_INTERVAL_NO_TIMEOUT);
-  }
-
-  // If we get here, DeliverFrame received at least one frame.
-  PR_Unlock(mSnapshotLock);
-  PR_DestroyCondVar(mSnapshotCondVar);
-  PR_DestroyLock(mSnapshotLock);
-
-  webrtc::ViEFile* vieFile = webrtc::ViEFile::GetInterface(mVideoEngine);
-  if (!vieFile) {
-    return NS_ERROR_FAILURE;
-  }
-
-  // Create a temporary file on the main thread and put the snapshot in it.
-  // See Run() in MediaEngineWebRTCVideo.h (sets mSnapshotPath).
-  NS_DispatchToMainThread(this, NS_DISPATCH_SYNC);
-
-  if (!mSnapshotPath) {
-    return NS_ERROR_FAILURE;
-  }
-
-  NS_ConvertUTF16toUTF8 path(*mSnapshotPath);
-  if (vieFile->GetCaptureDeviceSnapshot(mCaptureIndex, path.get()) < 0) {
-    delete mSnapshotPath;
-    mSnapshotPath = NULL;
-    return NS_ERROR_FAILURE;
-  }
-
-  // Stop the camera.
-  mViERender->StopRender(mCaptureIndex);
-  mViERender->RemoveRenderer(mCaptureIndex);
-
-  nsCOMPtr<nsIFile> file;
-  nsresult rv = NS_NewLocalFile(*mSnapshotPath, false, getter_AddRefs(file));
-
-  delete mSnapshotPath;
-  mSnapshotPath = NULL;
-
-  NS_ENSURE_SUCCESS(rv, rv);
-
-  NS_ADDREF(*aFile = new nsDOMFileFile(file));
-
   return NS_OK;
 }
 
 /**
  * Initialization and Shutdown functions for the video source, called by the
  * constructor and destructor respectively.
  */
 
diff --git a/dom/media/MediaManager.cpp b/dom/media/MediaManager.cpp
--- a/dom/media/MediaManager.cpp
+++ b/dom/media/MediaManager.cpp
@@ -72,27 +72,27 @@ private:
   already_AddRefed<nsIDOMGetUserMediaSuccessCallback> mSuccess;
   already_AddRefed<nsIDOMGetUserMediaErrorCallback> mError;
   const nsString mErrorMsg;
   uint64_t mWindowID;
 };
 
 /**
  * Invoke the "onSuccess" callback in content. The callback will take a
- * DOMBlob in the case of {picture:true}, and a MediaStream in the case of
- * {audio:true} or {video:true}. There is a constructor available for each
- * form. Do this only on the main thread.
+ * nsIDOMFile in the case of {picture:true}, which is the only case it handles.
+ * Callbacks for MediaStreams are handled by GetUserMediaStreamRunnable.
+ * Call this only on the main thread.
  */
 class SuccessCallbackRunnable : public nsRunnable
 {
 public:
   SuccessCallbackRunnable(
     already_AddRefed<nsIDOMGetUserMediaSuccessCallback> aSuccess,
     already_AddRefed<nsIDOMGetUserMediaErrorCallback> aError,
-    nsIDOMFile* aFile, uint64_t aWindowID)
+    already_AddRefed<nsIDOMFile> aFile, uint64_t aWindowID)
     : mSuccess(aSuccess)
     , mError(aError)
     , mFile(aFile)
     , mWindowID(aWindowID) {}
 
   NS_IMETHOD
   Run()
   {
@@ -476,43 +476,65 @@ public:
 
     NS_DispatchToMainThread(new GetUserMediaStreamRunnable(
       mSuccess, mError, aSource, mListeners, mWindowID, aTrackID
     ));
     return;
   }
 
   /**
-   * Allocates a video device, takes a snapshot and returns a DOMFile via
-   * a SuccessRunnable or an error via the ErrorRunnable. Off the main thread.
+   * Allocates a video device, asks engine to take a snapshot. Off the main
+   * thread. A callback is provided that will return the snapshot to content.
    */
   void
   ProcessGetUserMediaSnapshot(MediaEngineSource* aSource, int aDuration)
   {
     nsresult rv = aSource->Allocate();
     if (NS_FAILED(rv)) {
       NS_DispatchToMainThread(new ErrorCallbackRunnable(
         mSuccess, mError, NS_LITERAL_STRING("HARDWARE_UNAVAILABLE"), mWindowID
       ));
       return;
     }
 
     /**
      * Display picture capture UI here before calling Snapshot() - Bug 748835.
+     * Picture is returned and source is deallocated in the callback.
      */
-    nsCOMPtr<nsIDOMFile> file;
-    aSource->Snapshot(aDuration, getter_AddRefs(file));
-    aSource->Deallocate();
+    printf("\n!!! Going to call Snapshot !!!\n");
+    rv = aSource->Snapshot(aDuration, ProcessGetUserMediaSnapshotCallback, this);
+    if (rv == NS_ERROR_NOT_IMPLEMENTED) {
+      NS_DispatchToMainThread(new ErrorCallbackRunnable(
+        mSuccess, mError, NS_LITERAL_STRING("NOT_IMPLEMENTED"), mWindowID
+      ));
+    } else if (rv != NS_OK) {
+      NS_DispatchToMainThread(new ErrorCallbackRunnable(
+        mSuccess, mError, NS_LITERAL_STRING("HARDWARE_FAILURE"), mWindowID
+      ));
+    }
 
-    NS_DispatchToMainThread(new SuccessCallbackRunnable(
-      mSuccess, mError, file, mWindowID
-    ));
     return;
   }
 
+  /**
+   * Returns a DOMFile via a SuccessRunnable, on the main thread. This function
+   * is static because it is provided as a callback to the MediaEngine.
+   */
+  static void
+  ProcessGetUserMediaSnapshotCallback(already_AddRefed<nsIDOMFile> aFile, void* aData) {
+    printf("\n!!! received callback !!!\n");
+    GetUserMediaRunnable* gUMR = static_cast<GetUserMediaRunnable*>(aData);
+    if (gUMR != nullptr) {
+      gUMR->mDevice->GetSource()->Deallocate();
+      NS_DispatchToMainThread(new SuccessCallbackRunnable(
+        gUMR->mSuccess, gUMR->mError, aFile, gUMR->mWindowID
+      ));
+    }
+  }
+
 private:
   bool mAudio;
   bool mVideo;
   bool mPicture;
 
   already_AddRefed<nsIDOMGetUserMediaSuccessCallback> mSuccess;
   already_AddRefed<nsIDOMGetUserMediaErrorCallback> mError;
   StreamListeners* mListeners;
@@ -707,20 +729,19 @@ MediaManager::GetUserMedia(bool aPrivile
   } else {
     // Stream from default device from WebRTC backend.
     gUMRunnable = new GetUserMediaRunnable(
       audio, video, picture, onSuccess.forget(), onError.forget(), listeners,
       windowID
     );
   }
 
-  if (picture) {
-    // ShowFilePickerForMimeType() must run on the Main Thread! (on Android)
-    NS_DispatchToMainThread(gUMRunnable);
-  } else if (aPrivileged || fake) {
+  if (picture || aPrivileged || fake) {
+    // For pictures, privileged code and fake streams, no user permission is
+    // required.
     if (!mMediaThread) {
       nsresult rv = NS_NewThread(getter_AddRefs(mMediaThread));
       NS_ENSURE_SUCCESS(rv, rv);
     }
     mMediaThread->Dispatch(gUMRunnable, NS_DISPATCH_NORMAL);
   } else {
     // Ask for user permission, and dispatch runnable (or not) when a response
     // is received via an observer notification. Each call is paired with its
